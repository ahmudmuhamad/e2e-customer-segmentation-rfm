{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "FIGURES_PATH = Path(r\"E:\\ml_projects\\e2e-customer-segmentation-rfm\\reports\\figures\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0acddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df = pd.read_csv(r\"E:\\ml_projects\\e2e-customer-segmentation-rfm\\data\\interim\\customer_history.csv\")\n",
    "rfm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035bf40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig_name, dpi=300):\n",
    "    \"\"\"\n",
    "    Saves the current Matplotlib figure to the FIGURES_PATH.\n",
    "    \n",
    "    Args:\n",
    "        fig_name (str): The name of the file (without extension).\n",
    "        dpi (int): The resolution for the saved image.\n",
    "    \"\"\"\n",
    "    # Create the full file path\n",
    "    path = FIGURES_PATH / f\"{fig_name}.png\"\n",
    "    \n",
    "    # Save the figure\n",
    "    print(f\"Saving figure to: {path}\")\n",
    "    plt.savefig(path, format='png', dpi=dpi, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f31845",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(rfm_df['recency'], bins=30, kde=True)\n",
    "plt.title('Distribution of Recency')\n",
    "save_fig('recency_distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.log(rfm_df['frequency']), bins=30, kde=True)\n",
    "plt.title('Distribution of Log(Frequency)')\n",
    "save_fig('frequency_log_distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.log(rfm_df['monetary']), bins=30, kde=True)\n",
    "plt.title('Distribution of Log(Monetary)')\n",
    "save_fig('monetary_log_distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035268dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency vs. Monetary\n",
    "sns.scatterplot(data=rfm_df, x='frequency', y='monetary')\n",
    "plt.title('Frequency vs. Monetary')\n",
    "save_fig('frequency_vs_monetary_scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recency vs. Monetary\n",
    "sns.scatterplot(data=rfm_df, x='recency', y='monetary')\n",
    "plt.title('Recency vs. Monetary')\n",
    "save_fig('recency_vs_monetary_scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(y=rfm_df['recency'])\n",
    "plt.title('Recency Boxplot')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(y=rfm_df['frequency'])\n",
    "plt.title('Frequency Boxplot')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(y=rfm_df['monetary'])\n",
    "plt.title('Monetary Boxplot')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig('rfm_boxplots')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# This calculates log(1 + x)\n",
    "rfm_df['recency_log'] = np.log1p(rfm_df['recency'])\n",
    "rfm_df['frequency_log'] = np.log1p(rfm_df['frequency'])\n",
    "rfm_df['monetary_log'] = np.log1p(rfm_df['monetary'])\n",
    "\n",
    "feature_vector = ['monetary_log', 'recency_log', 'frequency_log']\n",
    "X_subset = rfm_df[feature_vector].values \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_subset)\n",
    "X_scaled = scaler.transform(X_subset)\n",
    "\n",
    "print(\"Data successfully transformed and scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b18a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09eb173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "xs =rfm_df.recency_log\n",
    "ys = rfm_df.frequency_log\n",
    "zs = rfm_df.monetary_log\n",
    "ax.scatter(xs, ys, zs, s=5)\n",
    "\n",
    "ax.set_xlabel('Recency')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Monetary')\n",
    "\n",
    "save_fig('rfm_3d_scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = np.isnan(X_scaled).any(axis=1)\n",
    "X_scaled = X_scaled[~nan_rows]\n",
    "\n",
    "# Verification (Optional):\n",
    "print(f\"X_scaled now has shape: {X_scaled.shape}\")\n",
    "print(\"NaN check:\", np.isnan(X_scaled).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "inertia = []\n",
    "K_range = range(2, 11) \n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia (WCSS)')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True)\n",
    "save_fig('kmeans_elbow_plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab9e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "k_range = range(3, 7)\n",
    "cluster_results = dict()\n",
    "print(f\"Running Silhouette Analysis for k in {list(k_range)}...\")\n",
    "cluster_results = dict()\n",
    "\n",
    "# --- 3. Set the Loop Range (Based on your Elbow plot) ---\n",
    "# We test k=3, 4, 5, and 6\n",
    "k_range = range(3, 7)\n",
    "\n",
    "print(f\"Running Silhouette Analysis for k in {list(k_range)}...\")\n",
    "\n",
    "for n_clusters in k_range:\n",
    "    # --- 4. Setup the Subplots (ax1 = silhouette, ax2 = 3D clusters) ---\n",
    "    fig = plt.figure(figsize=(20, 9))\n",
    "    \n",
    "    # Create the silhouette plot\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    \n",
    "    # *** KEY CHANGE: Create the 3D cluster plot ***\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "    fig.set_size_inches(20, 9)\n",
    "\n",
    "    # --- 5. Silhouette Plot (ax1) ---\n",
    "    ax1.set_xlim([-0.2, 1])\n",
    "    ax1.set_ylim([0, len(X_scaled) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize KMeans and fit\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10, n_init=10)\n",
    "    cluster_labels = clusterer.fit_predict(X_scaled)\n",
    "\n",
    "    # Calculate average silhouette score\n",
    "    silhouette_avg = silhouette_score(X_scaled, cluster_labels)\n",
    "    print(f\"For n_clusters = {n_clusters}, the average silhouette_score is : {silhouette_avg:.4f}\")\n",
    "\n",
    "    # Store results\n",
    "    cluster_results.update({n_clusters: {\n",
    "                                'cluster_center': clusterer.cluster_centers_,\n",
    "                                'silhouette_score': silhouette_avg,\n",
    "                                'labels': cluster_labels}\n",
    "                           })\n",
    "\n",
    "    # Get silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X_scaled, cluster_labels)\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to cluster i\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        # *** FIX for AttributeError ***\n",
    "        color = plt.get_cmap('Spectral')(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # Draw the vertical line for the average silhouette score\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # --- 6. 3D Cluster Visualization (ax2) ---\n",
    "    # *** FIX for AttributeError ***\n",
    "    colors = plt.get_cmap('Spectral')(cluster_labels.astype(float) / n_clusters)\n",
    "    \n",
    "    # Plot all 3 features\n",
    "    # Assumes: 0=Monetary, 1=Recency, 2=Frequency\n",
    "    ax2.scatter3D(X_scaled[:, 0], X_scaled[:, 1], X_scaled[:, 2], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                  c=colors, edgecolor='k')\n",
    "\n",
    "    # Plot the cluster centers\n",
    "    centers = clusterer.cluster_centers_\n",
    "    ax2.scatter3D(centers[:, 0], centers[:, 1], centers[:, 2], marker='o',\n",
    "                  c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "    \n",
    "    for i, c in enumerate(centers):\n",
    "        # Add cluster number label to the center\n",
    "        ax2.scatter3D(c[0], c[1], c[2], marker='$%d$' % i, alpha=1,\n",
    "                      s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"3D visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature 1 (Monetary_log)\")\n",
    "    ax2.set_ylabel(\"Feature 2 (Recency_log)\")\n",
    "    ax2.set_zlabel(\"Feature 3 (Frequency_log)\") # *** KEY CHANGE ***\n",
    "\n",
    "    # --- 7. Finalize and Save Plot ---\n",
    "    plt.suptitle((f\"Silhouette analysis for k = {n_clusters}\"),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Save the figure\n",
    "    save_fig(f\"silhouette_analysis_k_{n_clusters}\")\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "print(\"Silhouette analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Cluster Center Analysis ---\")\n",
    "\n",
    "\n",
    "for i in range(3, 7): \n",
    "    \n",
    "    # Check if the key exists (in case you change the loop)\n",
    "    if i in cluster_results:\n",
    "        print(\"=\"*30)\n",
    "        print(f\"FOR {i} NUMBER OF CLUSTERS\")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        # FIX 2: Use the correct dictionary name 'cluster_results'\n",
    "        centers_scaled = cluster_results[i]['cluster_center']\n",
    "        \n",
    "        # Inverse the scaling\n",
    "        centers_log_transformed = scaler.inverse_transform(centers_scaled)\n",
    "        \n",
    "        # FIX 3: Use np.expm1() to correctly inverse np.log1p()\n",
    "        # This transforms the centers from log-space back to their\n",
    "        # original real-world values (e.g., 10.5 days, 5 purchases)\n",
    "        centers_original = np.expm1(centers_log_transformed)\n",
    "        \n",
    "        # Create a DataFrame for easy reading\n",
    "        centers_df = pd.DataFrame(centers_original, columns=feature_vector)\n",
    "        \n",
    "        # Add a column for the cluster number\n",
    "        centers_df['cluster'] = [f'Cluster {j}' for j in range(i)]\n",
    "        print(centers_df.to_string())\n",
    "        \n",
    "        # Print the silhouette score\n",
    "        score = cluster_results[i]['silhouette_score']\n",
    "        print(f\"\\nSilhouette score for {i} clusters: {score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_features = rfm_df[['monetary_log', 'recency_log', 'frequency_log']]\n",
    "\n",
    "# 2. Drop NaNs, but keep track of the index\n",
    "rfm_features_clean = rfm_features.dropna()\n",
    "\n",
    "# 3. Scale this clean data\n",
    "scaler = preprocessing.StandardScaler().fit(rfm_features_clean)\n",
    "X_scaled = scaler.transform(rfm_features_clean)\n",
    "\n",
    "# 4. Re-run K-Means (only on the clean data)\n",
    "kmeans_final = KMeans(n_clusters=4, random_state=10, n_init=10)\n",
    "labels_k4 = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "# 5. Assign labels back using the .index\n",
    "rfm_df['cluster_4_labels'] = np.nan\n",
    "rfm_df.loc[rfm_features_clean.index, 'cluster_4_labels'] = labels_k4\n",
    "\n",
    "print(\"Labels assigned successfully!\")\n",
    "print(rfm_df['cluster_4_labels'].isnull().sum()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 1. Get the index of your 'clean' data (4331 rows) ---\n",
    "# (This is the same index we found in the last step)\n",
    "feature_vector = ['monetary_log', 'recency_log', 'frequency_log']\n",
    "clean_data_index = rfm_df[feature_vector].dropna().index\n",
    "\n",
    "# --- 2. Retrieve and assign labels for k=3 ---\n",
    "\n",
    "# Get the labels from your results dictionary\n",
    "labels_k3 = cluster_results[3]['labels'] \n",
    "\n",
    "# Create the new NaN column\n",
    "rfm_df['num_cluster3_labels'] = np.nan\n",
    "\n",
    "# Assign the 4331 labels to the correct 4331 rows\n",
    "rfm_df.loc[clean_data_index, 'num_cluster3_labels'] = labels_k3\n",
    "\n",
    "\n",
    "# --- 3. Retrieve and assign labels for k=5 ---\n",
    "\n",
    "# Get the labels from your results dictionary\n",
    "labels_k5 = cluster_results[5]['labels']\n",
    "\n",
    "# Create the new NaN column\n",
    "rfm_df['num_cluster5_labels'] = np.nan\n",
    "\n",
    "# Assign the 4331 labels to the correct 4331 rows\n",
    "rfm_df.loc[clean_data_index, 'num_cluster5_labels'] = labels_k5\n",
    "\n",
    "\n",
    "# --- 4. Verify the result ---\n",
    "print(\"Cluster labels for k=3 and k=5 assigned successfully.\")\n",
    "print(rfm_df.head())\n",
    "\n",
    "# Check the counts\n",
    "print(f\"\\nCluster 3 NaN count: {rfm_df['num_cluster3_labels'].isnull().sum()}\")\n",
    "print(f\"Cluster 5 NaN count: {rfm_df['num_cluster5_labels'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d0455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set the default renderer for Plotly\n",
    "pio.renderers.default = \"notebook_connected\" \n",
    "\n",
    "def plot_segment_distribution(df, cluster_col, field_col, cutoff_percentile=100):\n",
    "    \"\"\"\n",
    "    Creates an interactive Plotly box plot to compare the distribution of\n",
    "    a metric (e.g., 'recency') across different clusters.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Your main customer DataFrame\n",
    "        cluster_col (str): The column name of the cluster labels (e.g., 'num_cluster5_labels')\n",
    "        field_col (str): The metric you want to plot (e.g., 'recency', 'monetary')\n",
    "        cutoff_percentile (int): The percentile to use for capping outliers.\n",
    "                                 Default is 100 (no cutoff).\n",
    "                                 A value of 99 would remove the top 1% of outliers.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Generating plot for: {field_col} across {cluster_col}\")\n",
    "    \n",
    "    # Find the number of clusters (ignoring NaN)\n",
    "    cluster_labels = df[cluster_col].dropna().unique()\n",
    "    cluster_labels.sort() # Ensure clusters are in order (0, 1, 2, ...)\n",
    "    \n",
    "    traces = []\n",
    "    \n",
    "    # Loop through each cluster and create a box plot trace\n",
    "    for label in cluster_labels:\n",
    "        # 1. Filter the DataFrame for the specific cluster\n",
    "        cluster_data = df[df[cluster_col] == label][field_col]\n",
    "        \n",
    "        # 2. Handle NaNs and apply the percentile cutoff\n",
    "        if not cluster_data.empty:\n",
    "            # Drop any NaNs from this specific metric\n",
    "            cluster_data = cluster_data.dropna()\n",
    "            \n",
    "            # Calculate the cutoff value\n",
    "            cutoff_value = np.percentile(cluster_data, cutoff_percentile)\n",
    "            \n",
    "            # Filter the data\n",
    "            filtered_data = cluster_data[cluster_data <= cutoff_value]\n",
    "        \n",
    "            # 3. Create the trace\n",
    "            traces.append(go.Box(\n",
    "                y=filtered_data,\n",
    "                name=f'Cluster {int(label)}',\n",
    "                boxpoints=False, # Use 'all' or 'outliers' if you want to see points\n",
    "                jitter=0.5,\n",
    "                whiskerwidth=0.2,\n",
    "                marker=dict(size=2),\n",
    "                line=dict(width=1),\n",
    "            ))\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=f'Distribution of {field_col} by {cluster_col}',\n",
    "        yaxis=dict(\n",
    "            title=f'{field_col} (Outliers capped at {cutoff_percentile}th percentile)',\n",
    "            autorange=True,\n",
    "            showgrid=True,\n",
    "            zeroline=True,\n",
    "            gridcolor='rgb(230, 230, 230)',\n",
    "            gridwidth=1,\n",
    "            zerolinecolor='rgb(0, 0, 0)',\n",
    "            zerolinewidth=2,\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title='Cluster'\n",
    "        ),\n",
    "        margin=dict(l=60, r=30, b=80, t=100),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df['num_cluster5_labels'] = rfm_df['num_cluster5_labels'].astype('Int64')\n",
    "rfm_df['num_cluster3_labels'] = rfm_df['num_cluster3_labels'].astype('Int64')\n",
    "rfm_df['cluster_4_labels'] = rfm_df['cluster_4_labels'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00efa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set the default renderer for Plotly\n",
    "pio.renderers.default = \"notebook_connected\" \n",
    "\n",
    "def plot_segment_distribution(df, cluster_col, field_col, cutoff_percentile=100):\n",
    "    \"\"\"\n",
    "    Creates an interactive Plotly box plot to compare the distribution of\n",
    "    a metric (e.g., 'recency') across different clusters.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Your main customer DataFrame\n",
    "        cluster_col (str): The column name of the cluster labels (e.g., 'num_cluster5_labels')\n",
    "        field_col (str): The metric you want to plot (e.g., 'recency', 'monetary')\n",
    "        cutoff_percentile (int): The percentile to use for capping outliers.\n",
    "                                 Default is 100 (no cutoff).\n",
    "                                 A value of 99 would remove the top 1% of outliers.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Generating plot for: {field_col} across {cluster_col}\")\n",
    "    \n",
    "    # Find the number of clusters (ignoring NaN)\n",
    "    cluster_labels = df[cluster_col].dropna().unique()\n",
    "    \n",
    "    # *** FIX: Use np.sort() function instead of .sort() method ***\n",
    "    cluster_labels = np.sort(cluster_labels) # Ensure clusters are in order (0, 1, 2, ...)\n",
    "    \n",
    "    traces = []\n",
    "    \n",
    "    # Loop through each cluster and create a box plot trace\n",
    "    for label in cluster_labels:\n",
    "        # 1. Filter the DataFrame for the specific cluster\n",
    "        cluster_data = df[df[cluster_col] == label][field_col]\n",
    "        \n",
    "        # 2. Handle NaNs and apply the percentile cutoff\n",
    "        if not cluster_data.empty:\n",
    "            # Drop any NaNs from this specific metric\n",
    "            cluster_data = cluster_data.dropna()\n",
    "            \n",
    "            # Check if cluster_data is empty after dropping NaNs\n",
    "            if not cluster_data.empty:\n",
    "                # Calculate the cutoff value\n",
    "                cutoff_value = np.percentile(cluster_data, cutoff_percentile)\n",
    "                \n",
    "                # Filter the data\n",
    "                filtered_data = cluster_data[cluster_data <= cutoff_value]\n",
    "            else:\n",
    "                filtered_data = cluster_data\n",
    "        \n",
    "            # 3. Create the trace\n",
    "            traces.append(go.Box(\n",
    "                y=filtered_data,\n",
    "                name=f'Cluster {int(label)}',\n",
    "                boxpoints=False, # Use 'all' or 'outliers' if you want to see points\n",
    "                jitter=0.5,\n",
    "                whiskerwidth=0.2,\n",
    "                marker=dict(size=2),\n",
    "                line=dict(width=1),\n",
    "            ))\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=f'Distribution of {field_col} by {cluster_col}',\n",
    "        yaxis=dict(\n",
    "            title=f'{field_col} (Outliers capped at {cutoff_percentile}th percentile)',\n",
    "            autorange=True,\n",
    "            showgrid=True,\n",
    "            zeroline=True,\n",
    "            gridcolor='rgb(230, 230, 230)',\n",
    "            gridwidth=1,\n",
    "            zerolinecolor='rgb(0, 0, 0)',\n",
    "            zerolinewidth=2,\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title='Cluster'\n",
    "        ),\n",
    "        margin=dict(l=60, r=30, b=80, t=100),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    fig.show()\n",
    "\n",
    "# --- How to use the function ---\n",
    "\n",
    "# First, make sure your cluster label columns are numeric (not float)\n",
    "# This will help the loop work correctly by handling any NaNs\n",
    "# We assume rfm_df is your main DataFrame\n",
    "try:\n",
    "    rfm_df['num_cluster5_labels'] = rfm_df['num_cluster5_labels'].astype('Int64')\n",
    "    rfm_df['num_cluster3_labels'] = rfm_df['num_cluster3_labels'].astype('Int64')\n",
    "    rfm_df['cluster_4_labels'] = rfm_df['cluster_4_labels'].astype('Int64')\n",
    "except NameError:\n",
    "    print(\"Warning: 'rfm_df' not defined. Please ensure it exists.\")\n",
    "    # Create a dummy df for the script to be runnable\n",
    "    rfm_df = pd.DataFrame({\n",
    "        'cluster_4_labels': [0, 1, 0, 1, 2, 3, 2, np.nan],\n",
    "        'recency': [10, 300, 15, 250, 80, 120, 75, 50],\n",
    "        'frequency': [100, 2, 90, 1, 30, 20, 35, 5],\n",
    "        'monetary': [5000, 100, 4500, 50, 1000, 800, 1100, 200]\n",
    "    })\n",
    "\n",
    "\n",
    "# --- Analyze your k=4 model (the one your elbow plot suggested) ---\n",
    "# (Using a 99th percentile cutoff to remove extreme outliers for better viz)\n",
    "plot_segment_distribution(rfm_df, 'cluster_4_labels', 'recency', cutoff_percentile=99)\n",
    "plot_segment_distribution(rfm_df, 'cluster_4_labels', 'frequency', cutoff_percentile=99)\n",
    "plot_segment_distribution(rfm_df, 'cluster_4_labels', 'monetary', cutoff_percentile=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece94408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Calculate the mean RFM values for each cluster ---\n",
    "# We use the ORIGINAL RFM columns (not log) for interpretation\n",
    "segment_summary = rfm_df.groupby('cluster_4_labels')[['recency', 'frequency', 'monetary']].mean()\n",
    "\n",
    "# --- 2. Calculate the size (number of customers) of each cluster ---\n",
    "# .value_counts() will ignore NaNs by default\n",
    "segment_size = rfm_df['cluster_4_labels'].value_counts().sort_index()\n",
    "segment_summary['Count'] = segment_size\n",
    "segment_summary['Percent'] = (segment_summary['Count'] / segment_summary['Count'].sum()) * 100\n",
    "\n",
    "# --- 3. Display the final summary table ---\n",
    "# Sort by Monetary or Recency to make it easier to read\n",
    "segment_summary = segment_summary.sort_values(by='monetary', ascending=False)\n",
    "\n",
    "print(\"--- Segment Summary (k=4) ---\")\n",
    "print(segment_summary.to_markdown(floatfmt=\",.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328504b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_name_map = {\n",
    "    0: 'Champions',\n",
    "    1: 'Lost Customers',\n",
    "    2: 'New Customers',\n",
    "    3: 'At-Risk' \n",
    "}\n",
    "\n",
    "# Add the human-readable names to your DataFrame\n",
    "rfm_df['segment_name'] = rfm_df['cluster_4_labels'].map(segment_name_map)\n",
    "rfm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df.drop(columns = [\"num_cluster3_labels\", \"num_cluster5_labels\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_counts = rfm_df['segment_name'].value_counts()\n",
    "colors = sns.color_palette('viridis', len(segment_counts))\n",
    "\n",
    "# 3. Create the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    segment_counts, \n",
    "    labels=segment_counts.index, \n",
    "    autopct='%1.1f%%',  # Shows percentage with one decimal\n",
    "    startangle=140,       # Rotates the start of the pie\n",
    "    colors=colors,\n",
    "    wedgeprops={'edgecolor': 'white'} # Adds a thin white line between slices\n",
    ")\n",
    "\n",
    "# 4. Add title and ensure it's a circle\n",
    "plt.title('Customer Segment Proportions', fontsize=16, fontweight='bold')\n",
    "plt.axis('equal') # Ensures the pie is drawn as a circle\n",
    "\n",
    "# 5. Save the figure\n",
    "save_fig('customer_segment_proportions_pie')\n",
    "\n",
    "# 6. Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fca70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2e-customer-segmentation-rfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
